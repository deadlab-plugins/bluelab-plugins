# from tiny darknet cfg. Added custom deconvolution steps.

# Unet
# See: "SINGING VOICE SEPARATION WITH DEEPU-NET CONVOLUTIONAL NETWORKS - Andreas Jansson"
#https://pdfs.semanticscholar.org/83ea/11b45cba0fc7ee5d60f608edae9c1443861d.pdf


[net]
# training
width=256
height=32

# multichannel
channels=4

#1e-7
#learning_rate=1e-4
#batch=1
batch=20
momentum=0.9
decay=0.0001

adam=1
B1=0.9
B2=0.999
eps=1e-7

#learning_rate=1e-5
learning_rate=0.001
#test binary
#learning_rate=1e-4

#max_batches = 10000000
max_batches = 100000000

# default
policy=constant

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
filters=1024
size=1
stride=1
pad=1
activation=linear

#bluelab
#[reorg2]
#reverse=1
#stride_x=16
#stride_y=16
#flatten=1

[deconvolutional2]
batch_normalize=1
filters=256
size_x=3
size_y=3
stride_x=2
stride_y=2
pad=1
out_padding_x=1
out_padding_y=1
activation=relu
kernel_initializer=darknet_initializer

# new
[dropout]

[deconvolutional2]
batch_normalize=1
filters=64
size_x=3
size_y=3
stride_x=2
stride_y=2
pad=1
out_padding_x=1
out_padding_y=1
activation=relu
kernel_initializer=darknet_initializer

[deconvolutional2]
batch_normalize=1
filters=16
size_x=3
size_y=3
stride_x=2
stride_y=2
pad=1
out_padding_x=1
out_padding_y=1
activation=relu
kernel_initializer=darknet_initializer

[deconvolutional2]
filters=4
size_x=3
size_y=3
stride_x=2
stride_y=2
pad=1
out_padding_x=1
out_padding_y=1
activation=linear
kernel_initializer=darknet_initializer

[logistic]

#[metrics]
#type_cost=accuracy
#type_acc=accuracy
#global=0
