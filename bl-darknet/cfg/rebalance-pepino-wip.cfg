[net]
# Training
width=1024
height=20

# multichannel
channels=4

learning_rate=0.01

batch=1 #?
momentum=0.9
decay=0.0001 # ?
adam=1

clip=0.9 # TODO: implement it in darknet

B1=0.9
B2=0.999
eps=1e-7

max_batches = 10000000

#policy=constant


# pencoder begin

### 0
[batchnorm]

### 1
[convolutional]
filters=64
size=6 # (1025,1)
pad=1
activation=leaky
activation_alpha=0.2
#use_bias 0

### 2
[batchnorm]

### 3
[convolutional]
filters=64
size=6 # (1, 6)
pad=1
activation=leaky
activation_alpha=0.2
#use_bias 0

### 4
[batchnorm]

### 5
[reorg]
flatten=1

# pencoder end

# hencoder begin

###6
# hack (route after 1st batchnorm
[route]
layers=1

# hack: no need
#[batchnorm]

### 7
[convolutional]
filters=32
size=6 # (1, 21)
pad=1
activation=leaky
activation_alpha=0.2
#use_bias 0

#8
[batchnorm]

### 9
[convolutional]
filters=64
size=6 # (82, 1)
pad=1
activation=leaky
activation_alpha=0.2
#use_bias 0

### 10
[batchnorm]

### 11
[reorg]
flatten=1

# hencoder end

###12
[route]
layers=5,11

### 13
[activation]
activation=relu

###
###
###

##########################conv4
[convolutional]
# start_conv*8
filters=8
#filters=16
#filters=32
#filters=64
#ORIGIN
size=5
# TEST
#size=3
stride=2
pad=1
activation=leaky
activation_alpha=0.2
#batch_normalize=1

#[batchnorm]
[instancenorm]

##########################conv5
[convolutional]
filters=16
#filters=32
#filters=64
#filters=128
# ORIGIN
size=5
# TEST
#size=3
stride=2
pad=1
activation=leaky
activation_alpha=0.2
#batch_normalize=1

#[batchnorm]
[instancenorm]

##########################conv6
[convolutional]
# start_conv*32
filters=32
#filters=64
#filters=128
#filters=256
# ORIGIN
size=5
# TEST
#size=3
stride=2
pad=1
activation=leaky
activation_alpha=0.2
#batch_normalize=1

#[batchnorm]
[instancenorm]

##########################deconv1
[deconvolutional]
# start_conv*16
filters=16
#filters=32
#filters=64
#filters=128
# ORIGIN
size=5
# TEST
#size=3
stride=2
# to be checked
pad=1
# niko
out_padding=1
activation=relu
#batch_normalize=1

#[batchnorm]
[instancenorm]

[dropout]
probability=0.5
#probability=0.0
always_dropout=1

##########################deconv2
[route]
#layers=-1, -4
layers=-1, -6

[deconvolutional]
# start_conv*8
filters=8
#filters=16
#filters=32
#filters=64
# ORIGIN
size=5
# TEST
#size=3
stride=2
pad=1
out_padding=1
activation=relu
#batch_normalize=1

#[batchnorm]
[instancenorm]

[dropout]
probability=0.5
#probability=0.0
always_dropout=1

##########################deconv3
[route]
#layers=-1, -8
layers=-1, -12

[deconvolutional]
# start_conv*4
filters=4
#filters=8
#filters=16
#filters=32
# ORIGIN
size=5
# TEST
#size=3
stride=2
pad=1
out_padding=1
activation=relu
#batch_normalize=1

#[batchnorm]
[instancenorm]

##########################deconv4
[route]
#layers=-1, -11
layers=-1, -17

[deconvolutional]
# multichannel
#filters=1
filters=4
# ORIGIN
size=5
# TEST
#size=3

stride=2
pad=1
out_padding=1
# "logistic" is another name for "sigmoid"
activation=logistic

# must put [metrics] before [cost]!
[metrics]
type_cost=L1mask
#type_acc=L1mask_norm
type_acc=MSEmask
mean=1

#[cost]
#type=L1
#type=smooth
#type=L1mask
### default: 0 (warning, this flag modifies the result)
#mean=1 #0 #1

#[logistic]
