# From tiny darknet cfg. Try to exactly reverse all the tiny darknet steps
# - experiments with resample
# - try to use the unet system (with [route]), on tiny + tiny reversed

# Unet
# See: "SINGING VOICE SEPARATION WITH DEEPU-NET CONVOLUTIONAL NETWORKS - Andreas Jansson"
#https://pdfs.semanticscholar.org/83ea/11b45cba0fc7ee5d60f608edae9c1443861d.pdf


[net]
# training
width=256
height=32

# multichannel
channels=4

###############################
batch=128
#batch=1
subdivisions=1

momentum=0.9
decay=0.0005
max_crop=320

#learning_rate=0.
# for down
#learning_rate=0.0001
# for nodown
learning_rate=0.00001

policy=poly
power=4
max_batches=1600000
###############################

##1e-7
##learning_rate=1e-4
##batch=1
## for binary
#batch=20

#adam=1
#B1=0.9
#B2=0.999
#eps=1e-7
#momentum=0.9
#decay=0.0001

##learning_rate=1e-5
##orig
#learning_rate=0.001
##test binary
##learning_rate=1e-4

##max_batches = 10000000
#max_batches = 100000000

## default
##policy=constant

##from tiny
##learning_rate=0.1
##subdivisions=1
##momentum=0.9
##decay=0.0005
##max_crop=320
##policy=poly
##power=4

#[resample]
#stride_x=1
#stride_y=2

#[resample]
#stride_x=2
#stride_y=1
#reverse=1

# for "down"
#[resample]
#stride_x=2
#stride_y=2
#reverse=1

#0
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

#1
[maxpool]
size=2
stride=2

#2
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

#3
[maxpool]
size=2
stride=2

#4
[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

#5
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#6
[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=leaky

#7
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

#8
[maxpool]
size=2
stride=2

#9
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

#10
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#11
[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=leaky

#12
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky

#13
[maxpool]
size=2
stride=2

#14
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#15
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#16
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=leaky

#17
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky

#18
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

#19
[convolutional]
#bluelab
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
#activation=linear
activation=leaky

#bluelab

# new
#[dropout]

#20
[deconvolutional2]
batch_normalize=1
filters=128
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-3

#21
[deconvolutional2]
batch_normalize=1
filters=512
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-6

#22
[deconvolutional2]
batch_normalize=1
filters=64
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-9

#23
[deconvolutional2]
batch_normalize=1
filters=512
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-12

#24
[deconvolutional2]
batch_normalize=1
filters=64
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-15

#25
[deconvolutional2]
batch_normalize=1
filters=256
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-18

#26
[upsample]
stride=2

#27
[deconvolutional2]
batch_normalize=1
filters=32
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-23

#28
[deconvolutional2]
batch_normalize=1
filters=256
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-26

#29
[deconvolutional2]
batch_normalize=1
filters=32
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-29

#30
[deconvolutional2]
batch_normalize=1
filters=128
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-32

#31
[upsample]
stride=2

#32
[deconvolutional2]
batch_normalize=1
filters=16
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-37

#33
[deconvolutional2]
batch_normalize=1
filters=128
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-40

#34
[deconvolutional2]
batch_normalize=1
filters=16
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-43

#35
[deconvolutional2]
batch_normalize=1
filters=32
size_x=1
size_y=1
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-46

#36
[upsample]
stride=2

#37
[deconvolutional2]
batch_normalize=1
filters=16
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
activation=leaky

[route]
layers=-1,-51

#38
[upsample]
stride=2

#39
[deconvolutional2]
# bn at the end => avoid float overflow when big learning rate
#batch_normalize=1
filters=4
size_x=3
size_y=3
stride_x=1
stride_y=1
pad=1
#activation=leaky
activation=linear

# for "down"
#[resample]
#stride_x=2
#stride_y=2

#[resample]
#stride_x=2
#stride_y=1

#[resample]
#stride_x=1
#stride_y=2
#reverse=1

#40
[logistic]


#[metrics]
#type_cost=accuracy
#type_acc=accuracy
#global=0

#[metrics]
#type_cost=L1mask
#type_acc=MSEmask
## NOTE: global changed needs some code change in rebalance.c 
##global=0
#global=1
